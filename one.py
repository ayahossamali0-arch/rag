import os
import json
import re
import time
import threading
from dotenv import load_dotenv
from openai import OpenAI
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
from typing import List, Tuple

# ==============================
# 0ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# ==============================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if OPENAI_API_KEY is None:
    raise ValueError("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ OPENAI_API_KEY ÙÙŠ Ù…Ù„Ù .env")

client = OpenAI(api_key=OPENAI_API_KEY)

TOP_K = 5
SIMILARITY_THRESHOLD = 0.55
EMBED_MODEL_NAME = "intfloat/multilingual-e5-large"
DATA_FILE = os.path.join(os.path.dirname(__file__), "kk.json")

# ==============================
# 1ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¨Ù†Ø§Ø¡ FAISS
# ==============================
def load_data():
    if not os.path.exists(DATA_FILE):
        with open(DATA_FILE, "w", encoding="utf-8") as f:
            json.dump([], f, ensure_ascii=False, indent=2)
    try:
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError:
        print("âš ï¸ kk.json ØªØ§Ù„Ù â€” Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©...")
        with open(DATA_FILE, "w", encoding="utf-8") as f:
            json.dump([], f, ensure_ascii=False, indent=2)
        return []

data = load_data()
texts = [item["content"] for item in data] if data else ["Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯."]
model = SentenceTransformer(EMBED_MODEL_NAME)
text_embeddings = model.encode(texts, normalize_embeddings=True).astype("float32")

dimension = text_embeddings.shape[1]
index = faiss.IndexHNSWFlat(dimension, 32)
index.hnsw.efSearch = 64
index.add(text_embeddings)
last_modified = os.path.getmtime(DATA_FILE)

# ==============================
# 2ï¸âƒ£ ØªØ­Ø¯ÙŠØ« ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù€ FAISS
# ==============================
index_lock = threading.Lock()

def refresh_faiss_index_if_updated():
    global last_modified, index, text_embeddings, texts
    current_modified = os.path.getmtime(DATA_FILE)
    if current_modified != last_modified:
        print("ğŸ”„ Ø§ÙƒØªØ´Ø§Ù ØªØ¹Ø¯ÙŠÙ„ ÙÙŠ kk.json â€” ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙÙ‡Ø±Ø³...")
        new_data = load_data()
        if not new_data:
            print("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø¹Ø¯.")
            return
        new_texts = [item["content"] for item in new_data]
        new_embeddings = model.encode(new_texts, normalize_embeddings=True).astype("float32")
        new_index = faiss.IndexHNSWFlat(new_embeddings.shape[1], 32)
        new_index.hnsw.efSearch = 64
        new_index.add(new_embeddings)
        with index_lock:
            index = new_index
            text_embeddings = new_embeddings
            texts = new_texts
            last_modified = current_modified
        print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙÙ‡Ø±Ø³ ({len(texts)} Ø¹Ù†Ø§ØµØ±).")

# ==============================
# 3ï¸âƒ£ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ù†ÙˆØ§ÙŠØ§
# ==============================
ARABIC_DIACRITICS = re.compile(r"[Ù‹ÙŒÙÙÙÙÙ‘Ù’Ù€]")

def normalize_arabic(text: str) -> str:
    text = re.sub(ARABIC_DIACRITICS, "", text)
    text = text.replace("Ø¢", "Ø§").replace("Ø£", "Ø§").replace("Ø¥", "Ø§")
    text = text.replace("Ù‰", "ÙŠ").replace("Ø¤", "Ùˆ").replace("Ø¦", "ÙŠ")
    text = re.sub(r"[^\w\s\u0600-\u06FF]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def is_greeting_or_farewell(text: str) -> Tuple[bool, str]:
    greetings = ["Ù…Ø±Ø­Ø¨Ø§", "Ù‡Ù„Ø§", "Ø£Ù‡Ù„Ø§", "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…", "Ù‡Ø§ÙŠ", "hello", "hi"]
    farewells = ["Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©", "Ø¨Ø§ÙŠ", "ÙˆØ¯Ø§Ø¹Ø§", "goodbye", "bye", "Ø¥Ù„Ù‰ Ø§Ù„Ù„Ù‚Ø§Ø¡"]
    low = text.lower().strip()
    for g in greetings:
        if g in low:
            return True, "greeting"
    for f in farewells:
        if f in low:
            return True, "farewell"
    return False, ""

def detect_special_intent(text: str) -> Tuple[bool, str]:
    text_low = text.lower().strip()
    if any(k in text_low for k in ["Ø´ÙƒØ±Ø§", "Ù…Ø´ÙƒÙˆØ±", "thanks", "thx"]):
        return True, "thanks"
    if any(k in text_low for k in ["Ø¨Ø­Ø¨Ùƒ", "Ø§Ø­Ø¨Ùƒ", "i love you", "love you"]):
        return True, "love"
    if any(k in text_low for k in ["Ø±Ø§Ø¦Ø¹", "Ù…Ù…ØªØ§Ø²", "Ø¬Ù…ÙŠÙ„", "Ø°ÙƒÙŠ", "Ø¹Ø¨Ù‚Ø±ÙŠ"]):
        return True, "praise"
    if any(k in text_low for k in ["Ù…Ù…ÙƒÙ† Ø³Ø¤Ø§Ù„", "Ù…Ù…ÙƒÙ† Ø£Ø³Ø£Ù„", "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø£Ù† Ø£Ø³Ø£Ù„"]):
        return True, "offer_question"
    return False, ""

# ==============================
# 4ï¸âƒ£ Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆØ§Ù„Ø±Ø¯ Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„ØµÙˆØ± + Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¬Ø¯ÙŠØ¯
# ==============================
def rag_answer_final(user_question: str) -> str:
    threading.Thread(target=refresh_faiss_index_if_updated, daemon=True).start()

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ÙˆØ§ÙŠØ§
    is_special, kind = is_greeting_or_farewell(user_question)
    if is_special:
        return "ğŸ‘‹ Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ! ÙƒÙŠÙ Ø£Ø³ØªØ·ÙŠØ¹ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ" if kind == "greeting" else "ğŸ‘‹ Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©! Ø¨Ø§Ù„ØªÙˆÙÙŠÙ‚."

    intent_found, intent_type = detect_special_intent(user_question)
    if intent_found:
        return {
            "thanks": "ğŸ¤— Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø­Ø¨ ÙˆØ§Ù„Ø³Ø¹Ø©!",
            "love": "ğŸ˜Š Ø´ÙƒØ±Ø§Ù‹! Ù„ÙƒÙ†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ ÙÙ‚Ø· â¤ï¸.",
            "praise": "ğŸ™ Ø´ÙƒØ±Ø§Ù‹ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§ØªÙƒ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©!",
            "offer_question": "Ø£ÙƒÙŠØ¯ ØªÙØ¶Ù„ØŒ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ø¢Ù† ğŸ˜Š",
        }.get(intent_type, "ğŸ™‚ Ø­Ø§Ø¶Ø±.")

    # ØªØ­Ø³ÙŠÙ† ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI
    try:
        ai_understanding = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Ø£Ø¹Ø¯ ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ø£ÙˆØ¶Ø­ Ù„ØºØ±Ø¶ Ø§Ù„Ø¨Ø­Ø« Ø¯Ø§Ø®Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù†ØµÙŠØ©. Ù„Ø§ ØªØºÙŠÙ‘Ø± Ø§Ù„Ù…Ø¹Ù†Ù‰."},
                {"role": "user", "content": user_question}
            ]
        )
        refined_question = ai_understanding.choices[0].message.content.strip()
    except Exception:
        refined_question = user_question

    search_query = normalize_arabic(refined_question + " " + user_question)

    # Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
    for item in load_data():
        content_norm = normalize_arabic(item.get("content", ""))
        file_url = item.get("file_url", "")
        if search_query in content_norm or (file_url and search_query in file_url.lower()):
            if file_url:
                return f"<img src='{file_url}' style='max-width:300px;'>"
            return item.get("content", "")

    # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª
    try:
        q_emb = model.encode([search_query], normalize_embeddings=True).astype("float32")
        with index_lock:
            distances, indices = index.search(q_emb, TOP_K)

        results = [(int(idx), float(1 - dist)) for idx, dist in zip(indices[0], distances[0])]
        results = [r for r in results if r[0] >= 0]
        results = sorted(results, key=lambda x: x[1], reverse=True)

        if not results or results[0][1] < SIMILARITY_THRESHOLD:
            return "â— Ù„Ù… Ø£Ø¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø©ØŒ Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆØ¶ÙŠØ­ Ø³Ø¤Ø§Ù„Ùƒ Ø£ÙƒØ«Ø±ØŸ"

        best_idx = results[0][0]
        data_list = load_data()
        best_item = data_list[best_idx]

        if best_item.get("file_url"):
            return f"<img src='{best_item['file_url']}' style='max-width:300px;'>"

        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        try:
            optimized_answer = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ù‚Ø¯Ù‘Ù… Ø¬ÙˆØ§Ø¨Ø§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙ…Ø¨Ø§Ø´Ø±Ø§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ø·Ù‰."},
                    {"role": "user", "content": f"Ø§Ù„Ø³Ø¤Ø§Ù„: {user_question}\n\nØ§Ù„Ù†Øµ:\n{best_item.get('content', '')}"}
                ]
            )
            return optimized_answer.choices[0].message.content.strip()
        except Exception:
            return best_item.get("content", "")

    except Exception as e:
        return f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {e}"

# ==============================
# 5ï¸âƒ£ ØªØ´ØºÙŠÙ„ ØªÙØ§Ø¹Ù„ÙŠ
# ==============================
if __name__ == "__main__":
    print("ğŸ¤– Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ø°ÙƒÙŠ Ø¬Ø§Ù‡Ø²! Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.")
    print("ğŸŸ¢ Ø§ÙƒØªØ¨ 'Ø®Ø±ÙˆØ¬' Ù„Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©.")
    while True:
        user_q = input("ğŸ§‘â€ğŸ“: ").strip()
        if user_q.lower() in ["Ø®Ø±ÙˆØ¬", "exit", "quit"]:
            print("ğŸ¤–: Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø© ğŸ‘‹")
            break
        print("ğŸ¤–:", rag_answer_final(user_q))
